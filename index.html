
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>A Vocoder Based Method For Singing Voice Extraction</title>
        <!-- <link rel="stylesheet" type="text/css" href="../../css/blog-web.css" media="all"> -->
        <!-- <head> -->
    <link type="text/css" rel="stylesheet" href="css/style.css" />
    <style type="text/css">
    audio { width: 200px; }

    html {
    position: relative;
    min-width: 1024px;
    min-height: 768px;
    height: 100%;
}

    </style>
    <!-- </head> -->
    </head>
    <body>
    <center>
    <div id="blog-wrapper">
      <div id="blog-content">
          <h2>Audio Examples of paper: A Vocoder Based Method For Singing Voice Extraction</h2>
          <h3>Pritish Chandna, Merlijn Blaauw, Jordi Bonada, Emilia Gómez</h3>
          <h3>Music Technology Group, Universitat Pompeu Fabra, Barcelona</h3>
    </center>



  <h4>Examples From iKala Validation Set (In Mandarin Chinese)</h4>
  <p> These are examples from the iKala dataset, on which the system was trained and evaluated</p>


  <table>

  <tr>
    <td width="165px" style="padding-bottom: 40px;"></td>
    <td width="150px"><b>Mixture</b></td>
    <td width="150px"><b>Original vocals</b></td>
    <td width="150px"><b>Vocals extracted using sssynth</b></td>
    <td width="150px"><b>Vocals extracted using <a href="https://github.com/MTG/DeepConvSep">DeepConvSep</a> [1].</b></td>
    <td width="150px"><b>Vocals extracted using <a href="http://bass-db.gforge.inria.fr/fasst/">FASST</a> [2].</b></td>

    

  </tr>
  <tr>
    <td><b>21084_verse</b></td>
    <td>
  <audio controls preload="none" >
  <source src="audio/21084_verse_2_mix.mp3" type="audio/mpeg">
  Your browser does not support the audio element.
  </audio>
    </td>

    <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_ori.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td>
    <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_orif0.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td>
  <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_DCS.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td>
  <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_FASST.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td>
  </tr>

</table>

  <table>

  <tr>
    <td width="165px" style="padding-bottom: 40px;"></td>
    <td width="150px"><b>Mixture</b></td>
    <td width="150px"><b>Original vocals</b></td>
    <td width="150px"><b>Vocals extracted using sssynth</b></td>
<!--     <td width="150px"><b>Vocals extracted using <a href="https://github.com/MTG/DeepConvSep">DeepConvSep</a> [1].</b></td>
    <td width="150px"><b>Vocals extracted using <a href="http://bass-db.gforge.inria.fr/fasst/">FASST</a> [2].</b></td> -->

<h4>Real World Examples (From MedleyDB [3])</h4>
<p> These examples showcase the application of the methodology on a real world example. The system has neither been trained on the singer nor the langauge, but still gives a decent output.</p>

  </tr>
  <tr>
    <td><b>MusicDelta_Reggae</b></td>
    <td>
  <audio controls preload="none" >
  <source src="audio/MusicDelta_Reggae.wav_mixture.wav" type="audio/wav">
  Your browser does not support the audio element.
  </audio>
    </td>

    <td>
  <audio controls preload="none">
  <source src="audio/MusicDelta_Reggae.wav_ori_vocals.wav" type="audio/wav">
  Your browser does not support the audio element.
  </audio>
    </td>
    <td>
  <audio controls preload="none">
  <source src="audio/MusicDelta_Reggae_synth_ori_f0.wav" type="audio/wav">
  Your browser does not support the audio element.
  </audio>
    </td>
<!--   <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_DCS.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td>
  <td>
  <audio controls preload="none">
  <source src="audio/21084_verse_2_FASST.mp3" type="audio/mp3">
  Your browser does not support the audio element.
  </audio>
    </td> -->
  </tr>

</table>
  <table>

  <tr>
    <!-- <td width="165px" style="padding-bottom: 40px;"></td> -->
    <td width="150px">   

      <figure>

      <div id="container" align="left">
   <img src="images/SDR.png" alt="SDR" width="470" height="300"/> 
   <figcaption>
    The  SDR  metric  from  the  BSS  Eval  toolkit  for  the three systems to be compared.
   </figcaption>
    </figure>
 </td>
    <td width="150px"> 
  
   <img src="images/SAR.png" alt="SDR"  width="470" height="300" /> 
   <figcaption>
    The  SAR  metric  from  the  BSS  Eval  toolkit  for  the three systems to be compared.
   </figcaption>
     </div>         
  </figure>
  </tr>
  <tr>
    <!-- <td width="165px" style="padding-bottom: 40px;"></td> -->
    <td width="150px">   

      <figure>

      <div id="container" align="left">
   <img src="images/SIR.png" alt="SDR" width="470" height="300"/> 
   <figcaption>
    The SIR metric from the BSS Eval toolkit for the three systems to be compared.
   </figcaption>
    </figure>
 </td>
    <td width="150px"> 
  
   <img src="images/MCD.png" alt="SDR"  width="470" height="300" /> 
   <figcaption>
    The  Mel Cepstral Distrotion (MCD), in dB, for the three systems compared .
   </figcaption>
     </div>         
  </figure>
  </tr>

</table>




          <!-- <img src= alt="SDR"> -->

          <!-- <img src="SAR.png" alt="SAR"> -->


          <p>[1] P. Chandna, M. Miron, J. Janer, and E. Gómez, “Monoaural audio source separation using deep convolutional neural networks” International Conference on Latent Variable Analysis and Signal Separation, 2017.</p>
          <p>[2] A. Ozerov, E.Vincent, and F. Bimbot,    “A  general  flexible  framework  for  the  handling of prior information in audio source separation,”IEEETransactions on Audio, Speech, and Language Process-ing, vol. 20, no. 4, pp. 1118–1133, 2012.</p>
          <p>[3] R. Bittner, J. Salamon, M. Tierney, M. Mauch, C. Cannam and J. P. Bello, "MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research", in 15th International Society for Music Information Retrieval Conference, Taipei, Taiwan, Oct. 2014.</p>

      </div>
      
      <div id="blog-bg-footer">
        <div id="blog-footer">
          <p>
            Last updated:&nbsp;
            <script language="JavaScript">
            document.write(String(document.lastModified))</script>
          </p>
        </div>
      </div>
    </div>
    </body>
</html>